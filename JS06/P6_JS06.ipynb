{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaa0616",
   "metadata": {},
   "source": [
    "## Tugas\n",
    "\n",
    "1. Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data\n",
    "2. Download data dan load CSV filenya (pilih dataset yang pertama dari dua dataset)\n",
    "3. Pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler\n",
    "4. Lakukan pencarian track terdekat dan bandingkan hasilnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7530e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ASUS\\.cache\\kagglehub\\datasets\\bwandowando\\spotify-songs-with-attributes-and-lyrics\\versions\\19\n",
      "Exact NN done in 394.998 s\n",
      "Exact NN done in 394.998 s\n",
      "Annoy done in 28.851 s\n",
      "Annoy done in 28.851 s\n",
      "HNSW done in 35.438 s\n",
      "HNSW done in 35.438 s\n",
      "\n",
      "Top-5 neighbors for first song:\n",
      "Exact NN: [     0 394553 764272 837727 749223]\n",
      "Annoy:    [0, 394553, 764272, 837727, 61511]\n",
      "HNSW:     [     0 394553 764272 837727 749223]\n",
      "FAISS:    [     0 394553 764272 837727 749223]\n",
      "\n",
      "Top-5 neighbors for first song:\n",
      "Exact NN: [     0 394553 764272 837727 749223]\n",
      "Annoy:    [0, 394553, 764272, 837727, 61511]\n",
      "HNSW:     [     0 394553 764272 837727 749223]\n",
      "FAISS:    [     0 394553 764272 837727 749223]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "from annoy import AnnoyIndex\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bwandowando/spotify-songs-with-attributes-and-lyrics\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(path + '/songs_with_attributes_and_lyrics.csv')  # pastikan dataset tersedia\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k = 10  # jumlah nearest neighbors\n",
    "\n",
    "# -------------------------------\n",
    "# Exact Nearest Neighbor (brute-force)\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "nn.fit(X_scaled)\n",
    "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
    "time_exact = time.time() - start\n",
    "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# Annoy\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "f = X_scaled.shape[1]\n",
    "index_annoy = AnnoyIndex(f, 'euclidean')\n",
    "for i, v in enumerate(X_scaled):\n",
    "    index_annoy.add_item(i, v)\n",
    "index_annoy.build(10)\n",
    "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
    "time_annoy = time.time() - start\n",
    "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# HNSW\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
    "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
    "p_hnsw.add_items(X_scaled)\n",
    "p_hnsw.set_ef(200)\n",
    "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
    "time_hnsw = time.time() - start\n",
    "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# FAISS IVF\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
    "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 100)  # nlist=100 sebagai argumen posisi\n",
    "index_faiss.train(X_scaled.astype('float32'))\n",
    "index_faiss.add(X_scaled.astype('float32'))\n",
    "index_faiss.nprobe = 10\n",
    "dist_faiss, idx_faiss = index_faiss.search(X_scaled.astype('float32'), k)\n",
    "time_faiss = time.time() - start\n",
    "\n",
    "# -------------------------------\n",
    "# Contoh tampilkan top-5 neighbors dari item pertama\n",
    "# -------------------------------\n",
    "print(\"\\nTop-5 neighbors for first song:\")\n",
    "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
    "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
    "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
    "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30098c3",
   "metadata": {},
   "source": [
    "## Analisis\n",
    "\n",
    "- annoy paling cepat untuk pemrosesan data yang besar\n",
    "- keempat algoritma yang ada, memiliki akurasi yang mirip - mirip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
