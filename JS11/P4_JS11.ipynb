{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be2fcda",
   "metadata": {},
   "source": [
    "## Pengantar\n",
    "\n",
    "Setelah kita memahami proses klasifikasi dengan menggunakan SVM, selanjutnya kita akan belajar melakukan klasifikasi dengan data riil berupa citra wajah. Dataset yang akan digunakan adalah dataset wajah-wajah dari ribuan publik figur.\n",
    "\n",
    "**NB:** Anda mungkin memerlukan waktu yang cukup lama untuk mengunduh dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29aaef6",
   "metadata": {},
   "source": [
    "## Langkah 0 - Unduh Dataset\n",
    "\n",
    "Dataset yang digunakan dapat diunduh secara langsung melalui scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8228b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(len(faces.target_names))\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c7a5c",
   "metadata": {},
   "source": [
    "## Langkah 1 - Inspeksi Citra Wajah\n",
    "\n",
    "Lakukan inspeksi citra wajah yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contoh wajah yang digunakan\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7cf37",
   "metadata": {},
   "source": [
    "## Langkah 2 - Pra Pengolahan Data\n",
    "\n",
    "Pada tahap ini, kita akan mencoba melakukan proses pra pengolahan data sederhana dengan menggunakan Principal Component Analysis (PCA). PCA akan memproyeksikan fitur dengan resolusi tinggi (banyak dimensi) ke dalam principal component atau fitur yang dianggap penting saja. Metode PCA sering juga disebut sebagai metode reduksi dimensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "\n",
    "# Pipeline digunakan untuk melakukan proses secara bertahap dalam\n",
    "# 1 eksekusi fungsi secara langsung\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec3fc4",
   "metadata": {},
   "source": [
    "## Langkah 3 - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pemisahan data training dan data testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcefcb0",
   "metadata": {},
   "source": [
    "## Langkah 4 - Pembuatan Model + Tunning\n",
    "\n",
    "Pada langkah ini, kita akan mensimulasikan pembuatan model dan hyperparameter tunning secara langsung untuk mendapatkan nilai hyperparameter yang terbaik. Nilai tersebut dapat dicapai salah satunya dengan menggunakan teknik `GridSearch`. GridSearch akan mencoba setiap kombinasi hyperparameter terbaik dengan cara melakukan pengujian performansinya satu per satu. Cara ini mudah akan tetapi memakan waktu yang lama dan komputasi yang cukup tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87edf14d",
   "metadata": {},
   "source": [
    "Sehingga didapatkan informasi bahwa, hyperparameter terbaik dari model SVM yang kita buat adalah dengan, C=5 dan Gamma=0.001 dengan tingkat akurasi 82.88%.\n",
    "\n",
    "Gunakan model terbaik tersebut untuk proses prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "yfit = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c51408",
   "metadata": {},
   "source": [
    "## Langkah 5 - Cek Hasil Prediksi\n",
    "\n",
    "Cek hasil prediksi pada citra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91059d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil label pada data testing\n",
    "\n",
    "fig, ax = plt.subplots(4, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10492c",
   "metadata": {},
   "source": [
    "Contoh di atas hanya menunjukkan satu data dengan label salah. Selanjutnya, kita akan mengukur performa model dengan classification report dan confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89008b62",
   "metadata": {},
   "source": [
    "## Langkah 6 - Cek Performansi\n",
    "\n",
    "Pertama, cek performansi dengan `classification_report` dari sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, yfit,\n",
    "                            target_names=faces.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbe5bd",
   "metadata": {},
   "source": [
    "Dari tabel tersebut, kita mendapatkan informasi terkait dengan akurasi keseluruhan, presisi, recall, dan f1-score untuk setiap label.\n",
    "\n",
    "Selanjutnya, kita dapat menggunakan confusion matrix untuk mengetahui label-label yang terklasifikasi dengan benar dan tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bentuk confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
